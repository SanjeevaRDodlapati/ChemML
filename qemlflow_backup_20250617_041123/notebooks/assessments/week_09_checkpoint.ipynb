{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChemML Integration Setupimport chemmlprint(f'ðŸ§ª ChemML {chemml.__version__} loaded for this notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de3158",
   "metadata": {},
   "source": [
    "# Week 9 Checkpoint: Advanced Applications and Case Studies\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply integrated computational approaches to real drug discovery problems\n",
    "- Analyze complex pharmaceutical case studies\n",
    "- Develop end-to-end computational workflows\n",
    "- Validate and interpret multi-scale modeling results\n",
    "\n",
    "## Progress Tracking Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 9 Progress Tracking\n",
    "week_number = 9\n",
    "week_topic = \"Advanced Applications and Case Studies\"\n",
    "total_points = 100\n",
    "tasks_completed = 0\n",
    "current_score = 0\n",
    "\n",
    "# Task completion tracking\n",
    "task_scores = {\n",
    "    'task_1_covid_case_study': 0,\n",
    "    'task_2_cancer_drug_design': 0,\n",
    "    'task_3_personalized_medicine': 0,\n",
    "    'task_4_regulatory_modeling': 0\n",
    "}\n",
    "\n",
    "# Skills assessment\n",
    "skills_developed = {\n",
    "    'case_study_analysis': False,\n",
    "    'integrated_workflows': False,\n",
    "    'personalized_approaches': False,\n",
    "    'regulatory_compliance': False\n",
    "}\n",
    "\n",
    "print(f\"Week {week_number}: {week_topic}\")\n",
    "print(f\"Progress: {tasks_completed}/4 tasks completed\")\n",
    "print(f\"Current Score: {current_score}/{total_points} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe3cbb",
   "metadata": {},
   "source": [
    "## Task 1: COVID Drug Discovery Case Study (25 points)\n",
    "\n",
    "Analyze SARS-CoV-2 main protease (Mpro) inhibitor discovery using computational methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "import seaborn as sns\n",
    "\n",
    "class COVIDDrugDiscovery:\n",
    "    \"\"\"COVID-19 drug discovery case study analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mpro_inhibitors = []\n",
    "        self.binding_affinities = []\n",
    "        self.drug_properties = {}\n",
    "        self.screening_results = {}\n",
    "    \n",
    "    def generate_mpro_dataset(self, n_compounds=1000):\n",
    "        \"\"\"Generate synthetic Mpro inhibitor dataset\"\"\"\n",
    "        \n",
    "        # Known Mpro inhibitor scaffolds (simplified)\n",
    "        scaffolds = [\n",
    "            'CC(C)CC(NC(=O)C(F)(F)F)C(=O)N',  # Peptidomimetic\n",
    "            'Cc1ccc(S(=O)(=O)N)cc1',  # Sulfonamide\n",
    "            'NC(=O)c1ccc(Cl)cc1',  # Benzamide\n",
    "            'CC(=O)Nc1ccc(O)cc1',  # Acetaminophen-like\n",
    "            'COc1ccc(CC(=O)N)cc1'   # Phenylacetamide\n",
    "        ]\n",
    "        \n",
    "        compounds = []\n",
    "        activities = []\n",
    "        \n",
    "        for i in range(n_compounds):\n",
    "            # Create variations of scaffolds\n",
    "            base_scaffold = np.random.choice(scaffolds)\n",
    "            \n",
    "            # Generate molecular properties\n",
    "            mol = Chem.MolFromSmiles(base_scaffold)\n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            mw = Descriptors.MolWt(mol)\n",
    "            logp = Descriptors.MolLogP(mol)\n",
    "            hbd = Descriptors.NumHDonors(mol)\n",
    "            hba = Descriptors.NumHAcceptors(mol)\n",
    "            \n",
    "            # Simulate binding affinity (IC50 in Î¼M)\n",
    "            # Better properties generally lead to better binding\n",
    "            activity_score = 0\n",
    "            \n",
    "            # Molecular weight preference (300-500 Da)\n",
    "            if 300 <= mw <= 500:\n",
    "                activity_score += 2\n",
    "            elif mw > 600:\n",
    "                activity_score -= 3\n",
    "                \n",
    "            # LogP preference (1-4)\n",
    "            if 1 <= logp <= 4:\n",
    "                activity_score += 2\n",
    "            elif logp > 5:\n",
    "                activity_score -= 2\n",
    "                \n",
    "            # H-bond donors/acceptors\n",
    "            if hbd <= 3 and hba <= 8:\n",
    "                activity_score += 1\n",
    "                \n",
    "            # Add random variation\n",
    "            activity_score += np.random.normal(0, 2)\n",
    "            \n",
    "            # Convert to IC50 (lower is better)\n",
    "            ic50 = 10 ** (2 - activity_score) + np.random.lognormal(0, 0.5)\n",
    "            \n",
    "            compounds.append({\n",
    "                'smiles': base_scaffold,\n",
    "                'molecular_weight': mw,\n",
    "                'logp': logp,\n",
    "                'hbd': hbd,\n",
    "                'hba': hba,\n",
    "                'ic50_um': ic50,\n",
    "                'pic50': -np.log10(ic50 * 1e-6)  # Convert to pIC50\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(compounds)\n",
    "    \n",
    "    def analyze_structure_activity(self, df):\n",
    "        \"\"\"Analyze structure-activity relationships\"\"\"\n",
    "        \n",
    "        # Create activity classification\n",
    "        df['activity_class'] = pd.cut(df['pic50'], \n",
    "                                    bins=[0, 5, 6, 7, 12], \n",
    "                                    labels=['Inactive', 'Weak', 'Moderate', 'Strong'])\n",
    "        \n",
    "        # Statistical analysis\n",
    "        correlations = df[['molecular_weight', 'logp', 'hbd', 'hba', 'pic50']].corr()\n",
    "        \n",
    "        # Visualizations\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # MW vs Activity\n",
    "        axes[0,0].scatter(df['molecular_weight'], df['pic50'], alpha=0.6)\n",
    "        axes[0,0].set_xlabel('Molecular Weight (Da)')\n",
    "        axes[0,0].set_ylabel('pIC50')\n",
    "        axes[0,0].set_title('Molecular Weight vs Activity')\n",
    "        \n",
    "        # LogP vs Activity  \n",
    "        axes[0,1].scatter(df['logp'], df['pic50'], alpha=0.6)\n",
    "        axes[0,1].set_xlabel('LogP')\n",
    "        axes[0,1].set_ylabel('pIC50')\n",
    "        axes[0,1].set_title('Lipophilicity vs Activity')\n",
    "        \n",
    "        # Activity distribution\n",
    "        df['activity_class'].value_counts().plot(kind='bar', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Activity Distribution')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Correlation heatmap\n",
    "        sns.heatmap(correlations, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
    "        axes[1,1].set_title('Property Correlations')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return correlations\n",
    "    \n",
    "    def virtual_screening_workflow(self, df, test_size=0.2):\n",
    "        \"\"\"Implement virtual screening workflow\"\"\"\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        # Prepare features\n",
    "        features = ['molecular_weight', 'logp', 'hbd', 'hba']\n",
    "        X = df[features]\n",
    "        y = df['pic50']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train model\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Evaluate\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Feature importance\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Prediction vs Actual\n",
    "        axes[0].scatter(y_test, y_pred, alpha=0.6)\n",
    "        axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "        axes[0].set_xlabel('Actual pIC50')\n",
    "        axes[0].set_ylabel('Predicted pIC50')\n",
    "        axes[0].set_title(f'Predictions (RÂ² = {r2:.3f})')\n",
    "        \n",
    "        # Feature importance\n",
    "        importance.plot(x='feature', y='importance', kind='bar', ax=axes[1])\n",
    "        axes[1].set_title('Feature Importance')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'mse': mse,\n",
    "            'r2': r2,\n",
    "            'feature_importance': importance\n",
    "        }\n",
    "\n",
    "# Task 1 Implementation\n",
    "print(\"=== Task 1: COVID Drug Discovery Case Study ===\")\n",
    "\n",
    "# Initialize case study\n",
    "covid_study = COVIDDrugDiscovery()\n",
    "\n",
    "# Generate Mpro inhibitor dataset\n",
    "print(\"\\n1. Generating Mpro inhibitor dataset...\")\n",
    "mpro_data = covid_study.generate_mpro_dataset(800)\n",
    "print(f\"Generated {len(mpro_data)} compounds\")\n",
    "print(\"\\nDataset preview:\")\n",
    "print(mpro_data.head())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(mpro_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Task 1 execution\n",
    "print(\"\\n2. Analyzing structure-activity relationships...\")\n",
    "correlations = covid_study.analyze_structure_activity(mpro_data)\n",
    "\n",
    "print(\"\\nKey correlations with activity (pIC50):\")\n",
    "activity_corr = correlations['pic50'].abs().sort_values(ascending=False)\n",
    "print(activity_corr[activity_corr.index != 'pic50'])\n",
    "\n",
    "print(\"\\n3. Running virtual screening workflow...\")\n",
    "screening_results = covid_study.virtual_screening_workflow(mpro_data)\n",
    "\n",
    "print(f\"\\nVirtual Screening Results:\")\n",
    "print(f\"RÂ² Score: {screening_results['r2']:.3f}\")\n",
    "print(f\"RMSE: {np.sqrt(screening_results['mse']):.3f}\")\n",
    "print(\"\\nTop features:\")\n",
    "print(screening_results['feature_importance'].head())\n",
    "\n",
    "# Update progress\n",
    "task_scores['task_1_covid_case_study'] = 25\n",
    "skills_developed['case_study_analysis'] = True\n",
    "tasks_completed += 1\n",
    "current_score += 25\n",
    "\n",
    "print(f\"\\nâœ“ Task 1 completed! Score: 25/25\")\n",
    "print(f\"Progress: {tasks_completed}/4 tasks completed\")\n",
    "print(f\"Current Score: {current_score}/{total_points} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ddb25",
   "metadata": {},
   "source": [
    "## Task 2: Cancer Drug Design Case Study (25 points)\n",
    "\n",
    "Design kinase inhibitors for cancer treatment using multi-target optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee943e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDrugDesign:\n",
    "    \"\"\"Cancer drug design focusing on kinase inhibitors\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.target_kinases = ['EGFR', 'HER2', 'ALK', 'ROS1', 'MET']\n",
    "        self.compound_library = []\n",
    "        self.selectivity_profiles = {}\n",
    "        self.toxicity_predictions = {}\n",
    "    \n",
    "    def generate_kinase_inhibitors(self, n_compounds=500):\n",
    "        \"\"\"Generate kinase inhibitor library\"\"\"\n",
    "        \n",
    "        # Kinase inhibitor scaffolds\n",
    "        scaffolds = {\n",
    "            'quinazoline': 'Nc1ncnc2ccccc12',  # EGFR-like\n",
    "            'pyrimidine': 'Nc1nccc(n1)c2ccccc2',  # Multi-kinase\n",
    "            'indole': 'c1ccc2[nH]ccc2c1',  # General kinase\n",
    "            'benzimidazole': 'c1ccc2[nH]cnc2c1',  # ALK-like\n",
    "            'triazine': 'c1nc(nc(n1)N)N'  # Broad spectrum\n",
    "        }\n",
    "        \n",
    "        compounds = []\n",
    "        \n",
    "        for i in range(n_compounds):\n",
    "            scaffold_name = np.random.choice(list(scaffolds.keys()))\n",
    "            base_smiles = scaffolds[scaffold_name]\n",
    "            \n",
    "            # Generate molecular properties\n",
    "            mol = Chem.MolFromSmiles(base_smiles)\n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            mw = Descriptors.MolWt(mol) + np.random.normal(150, 50)\n",
    "            logp = Descriptors.MolLogP(mol) + np.random.normal(1, 0.8)\n",
    "            hbd = Descriptors.NumHDonors(mol) + np.random.randint(0, 3)\n",
    "            hba = Descriptors.NumHAcceptors(mol) + np.random.randint(1, 4)\n",
    "            rotbonds = np.random.randint(2, 8)\n",
    "            \n",
    "            # Simulate kinase activities (IC50 in nM)\n",
    "            activities = {}\n",
    "            for kinase in self.target_kinases:\n",
    "                # Different scaffolds have different selectivity patterns\n",
    "                base_activity = np.random.lognormal(2, 1.5)  # Base IC50\n",
    "                \n",
    "                if scaffold_name == 'quinazoline' and kinase in ['EGFR', 'HER2']:\n",
    "                    base_activity *= 0.1  # More potent against EGFR family\n",
    "                elif scaffold_name == 'benzimidazole' and kinase == 'ALK':\n",
    "                    base_activity *= 0.05  # Selective for ALK\n",
    "                elif scaffold_name == 'pyrimidine':\n",
    "                    base_activity *= 0.3  # Multi-kinase activity\n",
    "                    \n",
    "                activities[kinase] = base_activity\n",
    "            \n",
    "            # Calculate selectivity metrics\n",
    "            ic50_values = list(activities.values())\n",
    "            best_ic50 = min(ic50_values)\n",
    "            selectivity_ratio = np.median(ic50_values) / best_ic50\n",
    "            \n",
    "            # Simulate ADMET properties\n",
    "            clogp = logp + np.random.normal(0, 0.5)\n",
    "            solubility = -0.5 * clogp + np.random.normal(0, 0.8)\n",
    "            permeability = logp * 0.3 + np.random.normal(0, 0.4)\n",
    "            cytotoxicity = np.random.lognormal(1, 0.8)  # CC50 in Î¼M\n",
    "            \n",
    "            compounds.append({\n",
    "                'compound_id': f'KI_{i:04d}',\n",
    "                'scaffold': scaffold_name,\n",
    "                'smiles': base_smiles,\n",
    "                'molecular_weight': mw,\n",
    "                'logp': logp,\n",
    "                'clogp': clogp,\n",
    "                'hbd': hbd,\n",
    "                'hba': hba,\n",
    "                'rotatable_bonds': rotbonds,\n",
    "                'best_ic50_nm': best_ic50,\n",
    "                'selectivity_ratio': selectivity_ratio,\n",
    "                'solubility_log': solubility,\n",
    "                'permeability': permeability,\n",
    "                'cytotoxicity_um': cytotoxicity,\n",
    "                **{f'{kinase}_ic50_nm': activities[kinase] for kinase in self.target_kinases}\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(compounds)\n",
    "    \n",
    "    def multi_parameter_optimization(self, df):\n",
    "        \"\"\"Optimize compounds using multi-parameter criteria\"\"\"\n",
    "        \n",
    "        # Define scoring criteria\n",
    "        scores = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        # Potency score (based on best IC50)\n",
    "        scores['potency'] = np.where(df['best_ic50_nm'] <= 10, 5,\n",
    "                           np.where(df['best_ic50_nm'] <= 50, 4,\n",
    "                           np.where(df['best_ic50_nm'] <= 100, 3,\n",
    "                           np.where(df['best_ic50_nm'] <= 500, 2, 1))))\n",
    "        \n",
    "        # Selectivity score\n",
    "        scores['selectivity'] = np.where(df['selectivity_ratio'] >= 100, 5,\n",
    "                               np.where(df['selectivity_ratio'] >= 50, 4,\n",
    "                               np.where(df['selectivity_ratio'] >= 20, 3,\n",
    "                               np.where(df['selectivity_ratio'] >= 10, 2, 1))))\n",
    "        \n",
    "        # Drug-likeness score (Lipinski-like)\n",
    "        scores['druglikeness'] = (\n",
    "            (df['molecular_weight'] <= 500).astype(int) +\n",
    "            (df['logp'] <= 5).astype(int) +\n",
    "            (df['hbd'] <= 5).astype(int) +\n",
    "            (df['hba'] <= 10).astype(int) +\n",
    "            (df['rotatable_bonds'] <= 7).astype(int)\n",
    "        )\n",
    "        \n",
    "        # ADMET score\n",
    "        scores['admet'] = (\n",
    "            (df['solubility_log'] >= -4).astype(int) * 2 +  # Solubility\n",
    "            (df['permeability'] >= 0).astype(int) * 2 +     # Permeability\n",
    "            (df['cytotoxicity_um'] >= 10).astype(int) * 1   # Low cytotoxicity\n",
    "        )\n",
    "        \n",
    "        # Calculate composite score\n",
    "        weights = {'potency': 0.3, 'selectivity': 0.25, 'druglikeness': 0.25, 'admet': 0.2}\n",
    "        \n",
    "        scores['composite'] = (\n",
    "            scores['potency'] * weights['potency'] +\n",
    "            scores['selectivity'] * weights['selectivity'] +\n",
    "            scores['druglikeness'] * weights['druglikeness'] +\n",
    "            scores['admet'] * weights['admet']\n",
    "        )\n",
    "        \n",
    "        # Add scores to dataframe\n",
    "        result_df = df.copy()\n",
    "        for col in scores.columns:\n",
    "            result_df[f'{col}_score'] = scores[col]\n",
    "            \n",
    "        return result_df.sort_values('composite_score', ascending=False)\n",
    "    \n",
    "    def analyze_optimization_results(self, df):\n",
    "        \"\"\"Analyze multi-parameter optimization results\"\"\"\n",
    "        \n",
    "        # Top compounds\n",
    "        top_10 = df.head(10)\n",
    "        \n",
    "        # Visualizations\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Score distribution\n",
    "        score_cols = ['potency_score', 'selectivity_score', 'druglikeness_score', 'admet_score']\n",
    "        df[score_cols].hist(bins=5, ax=axes[0,0], alpha=0.7)\n",
    "        axes[0,0].set_title('Score Distributions')\n",
    "        axes[0,0].legend(score_cols)\n",
    "        \n",
    "        # Composite score vs best IC50\n",
    "        scatter = axes[0,1].scatter(df['best_ic50_nm'], df['composite_score'], \n",
    "                                  c=df['selectivity_ratio'], cmap='viridis', alpha=0.6)\n",
    "        axes[0,1].set_xlabel('Best IC50 (nM)')\n",
    "        axes[0,1].set_ylabel('Composite Score')\n",
    "        axes[0,1].set_xscale('log')\n",
    "        axes[0,1].set_title('Optimization Landscape')\n",
    "        plt.colorbar(scatter, ax=axes[0,1], label='Selectivity Ratio')\n",
    "        \n",
    "        # Scaffold analysis\n",
    "        scaffold_scores = df.groupby('scaffold')['composite_score'].mean().sort_values(ascending=False)\n",
    "        scaffold_scores.plot(kind='bar', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Average Composite Score by Scaffold')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Property space coverage\n",
    "        axes[1,1].scatter(df['molecular_weight'], df['logp'], \n",
    "                         c=df['composite_score'], cmap='RdYlBu_r', alpha=0.6)\n",
    "        axes[1,1].set_xlabel('Molecular Weight')\n",
    "        axes[1,1].set_ylabel('LogP')\n",
    "        axes[1,1].set_title('Property Space Coverage')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return top_10[['compound_id', 'scaffold', 'best_ic50_nm', 'selectivity_ratio', \n",
    "                      'potency_score', 'selectivity_score', 'druglikeness_score', \n",
    "                      'admet_score', 'composite_score']]\n",
    "\n",
    "# Task 2 Implementation\n",
    "print(\"\\n=== Task 2: Cancer Drug Design Case Study ===\")\n",
    "\n",
    "# Initialize cancer drug design\n",
    "cancer_design = CancerDrugDesign()\n",
    "\n",
    "# Generate kinase inhibitor library\n",
    "print(\"\\n1. Generating kinase inhibitor library...\")\n",
    "kinase_data = cancer_design.generate_kinase_inhibitors(400)\n",
    "print(f\"Generated {len(kinase_data)} kinase inhibitors\")\n",
    "print(\"\\nLibrary preview:\")\n",
    "print(kinase_data[['compound_id', 'scaffold', 'molecular_weight', 'best_ic50_nm', 'selectivity_ratio']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c58e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Task 2 execution\n",
    "print(\"\\n2. Running multi-parameter optimization...\")\n",
    "optimized_compounds = cancer_design.multi_parameter_optimization(kinase_data)\n",
    "\n",
    "print(\"\\n3. Analyzing optimization results...\")\n",
    "top_compounds = cancer_design.analyze_optimization_results(optimized_compounds)\n",
    "\n",
    "print(\"\\nTop 5 Optimized Compounds:\")\n",
    "print(top_compounds.head().round(3))\n",
    "\n",
    "print(\"\\nOptimization Summary:\")\n",
    "print(f\"Total compounds evaluated: {len(optimized_compounds)}\")\n",
    "print(f\"Compounds with composite score > 3.0: {len(optimized_compounds[optimized_compounds['composite_score'] > 3.0])}\")\n",
    "print(f\"Best compound score: {optimized_compounds['composite_score'].max():.3f}\")\n",
    "print(f\"Median selectivity ratio: {optimized_compounds['selectivity_ratio'].median():.1f}\")\n",
    "\n",
    "# Scaffold performance analysis\n",
    "print(\"\\nScaffold Performance:\")\n",
    "scaffold_perf = optimized_compounds.groupby('scaffold').agg({\n",
    "    'composite_score': 'mean',\n",
    "    'best_ic50_nm': 'median',\n",
    "    'selectivity_ratio': 'median'\n",
    "}).round(3)\n",
    "print(scaffold_perf)\n",
    "\n",
    "# Update progress\n",
    "task_scores['task_2_cancer_drug_design'] = 25\n",
    "skills_developed['integrated_workflows'] = True\n",
    "tasks_completed += 1\n",
    "current_score += 25\n",
    "\n",
    "print(f\"\\nâœ“ Task 2 completed! Score: 25/25\")\n",
    "print(f\"Progress: {tasks_completed}/4 tasks completed\")\n",
    "print(f\"Current Score: {current_score}/{total_points} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97590abd",
   "metadata": {},
   "source": [
    "## Task 3: Personalized Medicine Applications (25 points)\n",
    "\n",
    "Develop pharmacogenomics-based drug selection and dosing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a86244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedMedicine:\n",
    "    \"\"\"Pharmacogenomics-based personalized medicine\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.genetic_variants = {}\n",
    "        self.drug_responses = {}\n",
    "        self.dosing_algorithms = {}\n",
    "        \n",
    "    def simulate_patient_cohort(self, n_patients=300):\n",
    "        \"\"\"Generate patient cohort with genetic variants\"\"\"\n",
    "        \n",
    "        # Key pharmacogenomic variants\n",
    "        variants = {\n",
    "            'CYP2D6': ['*1/*1', '*1/*2', '*1/*4', '*4/*4', '*2/*2'],  # Metabolizer status\n",
    "            'CYP2C19': ['*1/*1', '*1/*2', '*1/*3', '*2/*2', '*2/*3'],\n",
    "            'SLCO1B1': ['*1/*1', '*1/*5', '*5/*5'],  # Statin response\n",
    "            'VKORC1': ['GG', 'GA', 'AA'],  # Warfarin sensitivity\n",
    "            'DPYD': ['*1/*1', '*1/*2A', '*2A/*2A'],  # 5-FU toxicity\n",
    "            'UGT1A1': ['*1/*1', '*1/*28', '*28/*28']  # Irinotecan toxicity\n",
    "        }\n",
    "        \n",
    "        # Population frequencies (simplified)\n",
    "        frequencies = {\n",
    "            'CYP2D6': [0.35, 0.25, 0.20, 0.10, 0.10],\n",
    "            'CYP2C19': [0.40, 0.25, 0.15, 0.15, 0.05],\n",
    "            'SLCO1B1': [0.70, 0.25, 0.05],\n",
    "            'VKORC1': [0.25, 0.50, 0.25],\n",
    "            'DPYD': [0.85, 0.14, 0.01],\n",
    "            'UGT1A1': [0.60, 0.35, 0.05]\n",
    "        }\n",
    "        \n",
    "        patients = []\n",
    "        \n",
    "        for i in range(n_patients):\n",
    "            patient = {'patient_id': f'PT_{i:04d}'}\n",
    "            \n",
    "            # Assign genetic variants\n",
    "            for gene in variants:\n",
    "                patient[f'{gene}_genotype'] = np.random.choice(\n",
    "                    variants[gene], p=frequencies[gene]\n",
    "                )\n",
    "            \n",
    "            # Demographics\n",
    "            patient['age'] = np.random.randint(25, 80)\n",
    "            patient['weight'] = np.random.normal(70, 15)\n",
    "            patient['sex'] = np.random.choice(['M', 'F'])\n",
    "            patient['ethnicity'] = np.random.choice(['Caucasian', 'African', 'Asian', 'Hispanic'], \n",
    "                                                  p=[0.60, 0.15, 0.15, 0.10])\n",
    "            \n",
    "            # Comorbidities\n",
    "            patient['diabetes'] = np.random.random() < 0.15\n",
    "            patient['hypertension'] = np.random.random() < 0.25\n",
    "            patient['kidney_disease'] = np.random.random() < 0.08\n",
    "            patient['liver_disease'] = np.random.random() < 0.05\n",
    "            \n",
    "            patients.append(patient)\n",
    "            \n",
    "        return pd.DataFrame(patients)\n",
    "    \n",
    "    def predict_drug_response(self, patients_df, drug='warfarin'):\n",
    "        \"\"\"Predict drug response based on pharmacogenomics\"\"\"\n",
    "        \n",
    "        responses = []\n",
    "        \n",
    "        for _, patient in patients_df.iterrows():\n",
    "            if drug == 'warfarin':\n",
    "                response = self._predict_warfarin_dose(patient)\n",
    "            elif drug == 'clopidogrel':\n",
    "                response = self._predict_clopidogrel_response(patient)\n",
    "            elif drug == 'simvastatin':\n",
    "                response = self._predict_statin_response(patient)\n",
    "            else:\n",
    "                response = {'predicted_response': 'unknown'}\n",
    "                \n",
    "            response['patient_id'] = patient['patient_id']\n",
    "            responses.append(response)\n",
    "            \n",
    "        return pd.DataFrame(responses)\n",
    "    \n",
    "    def _predict_warfarin_dose(self, patient):\n",
    "        \"\"\"VKORC1/CYP2C19-based warfarin dosing\"\"\"\n",
    "        \n",
    "        # Base dose calculation\n",
    "        base_dose = 5.0  # mg/day\n",
    "        \n",
    "        # VKORC1 effect (main effect)\n",
    "        vkorc1 = patient['VKORC1_genotype']\n",
    "        if vkorc1 == 'AA':\n",
    "            vkorc1_factor = 0.6  # Low dose needed\n",
    "        elif vkorc1 == 'GA':\n",
    "            vkorc1_factor = 0.8  # Intermediate\n",
    "        else:  # GG\n",
    "            vkorc1_factor = 1.0  # Standard dose\n",
    "            \n",
    "        # CYP2C19 effect (metabolism)\n",
    "        cyp2c19 = patient['CYP2C19_genotype']\n",
    "        if '*2' in cyp2c19 or '*3' in cyp2c19:\n",
    "            cyp_factor = 1.2  # Poor metabolizer, needs higher dose\n",
    "        else:\n",
    "            cyp_factor = 1.0\n",
    "            \n",
    "        # Age effect\n",
    "        age_factor = 1.0 - (patient['age'] - 40) * 0.01 if patient['age'] > 40 else 1.0\n",
    "        \n",
    "        # Weight effect\n",
    "        weight_factor = patient['weight'] / 70.0\n",
    "        \n",
    "        predicted_dose = base_dose * vkorc1_factor * cyp_factor * age_factor * weight_factor\n",
    "        predicted_dose = max(1.0, min(15.0, predicted_dose))  # Safety bounds\n",
    "        \n",
    "        # Risk assessment\n",
    "        if vkorc1 == 'AA' or '*2' in cyp2c19:\n",
    "            risk_category = 'High risk - start low, monitor closely'\n",
    "        elif vkorc1 == 'GA':\n",
    "            risk_category = 'Intermediate risk - standard monitoring'\n",
    "        else:\n",
    "            risk_category = 'Standard risk - routine monitoring'\n",
    "            \n",
    "        return {\n",
    "            'predicted_dose_mg': round(predicted_dose, 1),\n",
    "            'risk_category': risk_category,\n",
    "            'vkorc1_effect': vkorc1_factor,\n",
    "            'cyp2c19_effect': cyp_factor\n",
    "        }\n",
    "    \n",
    "    def _predict_clopidogrel_response(self, patient):\n",
    "        \"\"\"CYP2C19-based clopidogrel response\"\"\"\n",
    "        \n",
    "        cyp2c19 = patient['CYP2C19_genotype']\n",
    "        \n",
    "        if '*2' in cyp2c19 or '*3' in cyp2c19:\n",
    "            if cyp2c19 in ['*2/*2', '*2/*3']:\n",
    "                response = 'Poor metabolizer - consider alternative'\n",
    "                efficacy = 0.3\n",
    "            else:\n",
    "                response = 'Intermediate metabolizer - monitor closely'\n",
    "                efficacy = 0.6\n",
    "        else:\n",
    "            response = 'Normal metabolizer - standard therapy'\n",
    "            efficacy = 0.9\n",
    "            \n",
    "        return {\n",
    "            'predicted_response': response,\n",
    "            'predicted_efficacy': efficacy,\n",
    "            'alternative_recommended': '*2' in cyp2c19 or '*3' in cyp2c19\n",
    "        }\n",
    "    \n",
    "    def _predict_statin_response(self, patient):\n",
    "        \"\"\"SLCO1B1-based statin response\"\"\"\n",
    "        \n",
    "        slco1b1 = patient['SLCO1B1_genotype']\n",
    "        \n",
    "        if '*5' in slco1b1:\n",
    "            if slco1b1 == '*5/*5':\n",
    "                myopathy_risk = 0.25\n",
    "                recommendation = 'High risk - use lowest dose or alternative'\n",
    "            else:\n",
    "                myopathy_risk = 0.10\n",
    "                recommendation = 'Intermediate risk - start low dose'\n",
    "        else:\n",
    "            myopathy_risk = 0.02\n",
    "            recommendation = 'Standard risk - normal dosing'\n",
    "            \n",
    "        return {\n",
    "            'myopathy_risk': myopathy_risk,\n",
    "            'recommendation': recommendation,\n",
    "            'dose_reduction_needed': '*5' in slco1b1\n",
    "        }\n",
    "    \n",
    "    def analyze_population_responses(self, patients_df, responses_df, drug):\n",
    "        \"\"\"Analyze population-level pharmacogenomic patterns\"\"\"\n",
    "        \n",
    "        # Merge data\n",
    "        merged = patients_df.merge(responses_df, on='patient_id')\n",
    "        \n",
    "        if drug == 'warfarin':\n",
    "            self._analyze_warfarin_population(merged)\n",
    "        elif drug == 'clopidogrel':\n",
    "            self._analyze_clopidogrel_population(merged)\n",
    "        elif drug == 'simvastatin':\n",
    "            self._analyze_statin_population(merged)\n",
    "    \n",
    "    def _analyze_warfarin_population(self, data):\n",
    "        \"\"\"Analyze warfarin dosing patterns\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Dose by VKORC1 genotype\n",
    "        vkorc1_groups = data.groupby('VKORC1_genotype')['predicted_dose_mg']\n",
    "        vkorc1_groups.apply(list).apply(lambda x: axes[0,0].hist(x, alpha=0.7, label=x.name))\n",
    "        axes[0,0].set_xlabel('Predicted Dose (mg/day)')\n",
    "        axes[0,0].set_ylabel('Frequency')\n",
    "        axes[0,0].set_title('Warfarin Dose Distribution by VKORC1')\n",
    "        axes[0,0].legend()\n",
    "        \n",
    "        # Risk category distribution\n",
    "        risk_counts = data['risk_category'].value_counts()\n",
    "        risk_counts.plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%')\n",
    "        axes[0,1].set_title('Risk Category Distribution')\n",
    "        \n",
    "        # Age vs dose colored by genotype\n",
    "        for genotype in data['VKORC1_genotype'].unique():\n",
    "            subset = data[data['VKORC1_genotype'] == genotype]\n",
    "            axes[1,0].scatter(subset['age'], subset['predicted_dose_mg'], \n",
    "                            label=genotype, alpha=0.6)\n",
    "        axes[1,0].set_xlabel('Age')\n",
    "        axes[1,0].set_ylabel('Predicted Dose (mg/day)')\n",
    "        axes[1,0].set_title('Age vs Dose by VKORC1 Genotype')\n",
    "        axes[1,0].legend()\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary = data.groupby('VKORC1_genotype')['predicted_dose_mg'].agg(['mean', 'std', 'count'])\n",
    "        summary.plot(kind='bar', y='mean', yerr='std', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Mean Dose by VKORC1 Genotype')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Warfarin Dosing Summary:\")\n",
    "        print(summary.round(2))\n",
    "\n",
    "# Task 3 Implementation\n",
    "print(\"\\n=== Task 3: Personalized Medicine Applications ===\")\n",
    "\n",
    "# Initialize personalized medicine analysis\n",
    "personalized_med = PersonalizedMedicine()\n",
    "\n",
    "# Generate patient cohort\n",
    "print(\"\\n1. Generating patient cohort with genetic variants...\")\n",
    "patients = personalized_med.simulate_patient_cohort(250)\n",
    "print(f\"Generated {len(patients)} patients\")\n",
    "print(\"\\nCohort preview:\")\n",
    "print(patients[['patient_id', 'age', 'weight', 'sex', 'VKORC1_genotype', 'CYP2C19_genotype']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43869090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Task 3 execution\n",
    "print(\"\\n2. Predicting warfarin responses...\")\n",
    "warfarin_responses = personalized_med.predict_drug_response(patients, 'warfarin')\n",
    "print(\"\\nWarfarin response preview:\")\n",
    "print(warfarin_responses[['patient_id', 'predicted_dose_mg', 'risk_category']].head())\n",
    "\n",
    "print(\"\\n3. Analyzing population pharmacogenomic patterns...\")\n",
    "personalized_med.analyze_population_responses(patients, warfarin_responses, 'warfarin')\n",
    "\n",
    "print(\"\\n4. Clopidogrel response analysis...\")\n",
    "clopidogrel_responses = personalized_med.predict_drug_response(patients, 'clopidogrel')\n",
    "\n",
    "# Analyze CYP2C19 impact\n",
    "cyp_analysis = patients.merge(clopidogrel_responses, on='patient_id')\n",
    "cyp_impact = cyp_analysis.groupby('CYP2C19_genotype').agg({\n",
    "    'predicted_efficacy': 'mean',\n",
    "    'alternative_recommended': 'sum'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nCYP2C19 Impact on Clopidogrel:\")\n",
    "print(cyp_impact)\n",
    "\n",
    "print(\"\\n5. Statin myopathy risk assessment...\")\n",
    "statin_responses = personalized_med.predict_drug_response(patients, 'simvastatin')\n",
    "\n",
    "# Risk stratification\n",
    "risk_analysis = patients.merge(statin_responses, on='patient_id')\n",
    "high_risk = risk_analysis[risk_analysis['myopathy_risk'] > 0.1]\n",
    "\n",
    "print(f\"\\nStatin Risk Assessment:\")\n",
    "print(f\"Total patients: {len(patients)}\")\n",
    "print(f\"High risk patients (>10% myopathy risk): {len(high_risk)}\")\n",
    "print(f\"Percentage requiring dose modification: {len(high_risk)/len(patients)*100:.1f}%\")\n",
    "\n",
    "print(\"\\nSLCO1B1 genotype distribution:\")\n",
    "print(patients['SLCO1B1_genotype'].value_counts())\n",
    "\n",
    "# Clinical impact summary\n",
    "print(\"\\n=== Clinical Impact Summary ===\")\n",
    "print(f\"Warfarin high-risk patients: {len(warfarin_responses[warfarin_responses['risk_category'].str.contains('High')])}\")\n",
    "print(f\"Clopidogrel poor metabolizers: {len(clopidogrel_responses[clopidogrel_responses['alternative_recommended']])}\")\n",
    "print(f\"Statin high-risk patients: {len(statin_responses[statin_responses['myopathy_risk'] > 0.1])}\")\n",
    "\n",
    "# Update progress\n",
    "task_scores['task_3_personalized_medicine'] = 25\n",
    "skills_developed['personalized_approaches'] = True\n",
    "tasks_completed += 1\n",
    "current_score += 25\n",
    "\n",
    "print(f\"\\nâœ“ Task 3 completed! Score: 25/25\")\n",
    "print(f\"Progress: {tasks_completed}/4 tasks completed\")\n",
    "print(f\"Current Score: {current_score}/{total_points} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ae2fd",
   "metadata": {},
   "source": [
    "## Task 4: Regulatory Compliance Modeling (25 points)\n",
    "\n",
    "Implement computational models for regulatory submission and safety assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c17bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegulatoryModeling:\n",
    "    \"\"\"Computational models for regulatory compliance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.safety_models = {}\n",
    "        self.efficacy_models = {}\n",
    "        self.submission_data = {}\n",
    "        \n",
    "    def generate_clinical_trial_data(self, n_patients=500):\n",
    "        \"\"\"Generate synthetic clinical trial data\"\"\"\n",
    "        \n",
    "        # Patient demographics\n",
    "        patients = []\n",
    "        for i in range(n_patients):\n",
    "            patient = {\n",
    "                'patient_id': f'CT_{i:04d}',\n",
    "                'age': np.random.normal(55, 15),\n",
    "                'weight': np.random.normal(75, 12),\n",
    "                'sex': np.random.choice(['M', 'F']),\n",
    "                'baseline_severity': np.random.uniform(3, 8),  # Disease severity score\n",
    "                'treatment_arm': np.random.choice(['Active', 'Placebo'], p=[0.6, 0.4])\n",
    "            }\n",
    "            \n",
    "            # Simulate treatment response\n",
    "            if patient['treatment_arm'] == 'Active':\n",
    "                # Drug effect with individual variation\n",
    "                drug_effect = np.random.normal(-2.5, 1.0)  # Improvement in severity\n",
    "                response_prob = 0.65 + np.random.normal(0, 0.1)\n",
    "            else:\n",
    "                drug_effect = np.random.normal(-0.5, 0.8)  # Placebo effect\n",
    "                response_prob = 0.25 + np.random.normal(0, 0.1)\n",
    "                \n",
    "            patient['final_severity'] = max(0, patient['baseline_severity'] + drug_effect)\n",
    "            patient['response'] = np.random.random() < response_prob\n",
    "            patient['improvement'] = patient['baseline_severity'] - patient['final_severity']\n",
    "            \n",
    "            # Safety events\n",
    "            if patient['treatment_arm'] == 'Active':\n",
    "                ae_prob = 0.15 + (patient['age'] - 50) * 0.002  # Age increases AE risk\n",
    "            else:\n",
    "                ae_prob = 0.08\n",
    "                \n",
    "            patient['adverse_event'] = np.random.random() < ae_prob\n",
    "            patient['serious_ae'] = patient['adverse_event'] and np.random.random() < 0.1\n",
    "            \n",
    "            # Dropout\n",
    "            dropout_prob = 0.1 if patient['treatment_arm'] == 'Active' else 0.15\n",
    "            if patient['adverse_event']:\n",
    "                dropout_prob += 0.2\n",
    "            patient['completed_study'] = np.random.random() > dropout_prob\n",
    "            \n",
    "            patients.append(patient)\n",
    "            \n",
    "        return pd.DataFrame(patients)\n",
    "    \n",
    "    def efficacy_analysis(self, trial_data):\n",
    "        \"\"\"Perform regulatory-standard efficacy analysis\"\"\"\n",
    "        \n",
    "        # Primary efficacy endpoint: response rate\n",
    "        active_group = trial_data[trial_data['treatment_arm'] == 'Active']\n",
    "        placebo_group = trial_data[trial_data['treatment_arm'] == 'Placebo']\n",
    "        \n",
    "        # Response rates\n",
    "        active_response_rate = active_group['response'].mean()\n",
    "        placebo_response_rate = placebo_group['response'].mean()\n",
    "        \n",
    "        # Statistical test (Chi-square)\n",
    "        from scipy.stats import chi2_contingency\n",
    "        \n",
    "        contingency_table = pd.crosstab(trial_data['treatment_arm'], trial_data['response'])\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "        \n",
    "        # Effect size and confidence interval\n",
    "        active_n = len(active_group)\n",
    "        placebo_n = len(placebo_group)\n",
    "        \n",
    "        # Wilson score interval for proportions\n",
    "        def wilson_ci(successes, total, confidence=0.95):\n",
    "            z = 1.96  # 95% CI\n",
    "            p = successes / total\n",
    "            n = total\n",
    "            \n",
    "            center = (p + z**2 / (2*n)) / (1 + z**2 / n)\n",
    "            margin = z * np.sqrt((p*(1-p) + z**2/(4*n)) / n) / (1 + z**2 / n)\n",
    "            \n",
    "            return center - margin, center + margin\n",
    "        \n",
    "        active_ci = wilson_ci(active_group['response'].sum(), active_n)\n",
    "        placebo_ci = wilson_ci(placebo_group['response'].sum(), placebo_n)\n",
    "        \n",
    "        # Secondary endpoints\n",
    "        active_improvement = active_group['improvement'].mean()\n",
    "        placebo_improvement = placebo_group['improvement'].mean()\n",
    "        \n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, t_p_value = ttest_ind(active_group['improvement'], placebo_group['improvement'])\n",
    "        \n",
    "        results = {\n",
    "            'primary_endpoint': {\n",
    "                'active_response_rate': active_response_rate,\n",
    "                'placebo_response_rate': placebo_response_rate,\n",
    "                'difference': active_response_rate - placebo_response_rate,\n",
    "                'p_value': p_value,\n",
    "                'active_ci': active_ci,\n",
    "                'placebo_ci': placebo_ci,\n",
    "                'significant': p_value < 0.05\n",
    "            },\n",
    "            'secondary_endpoint': {\n",
    "                'active_improvement': active_improvement,\n",
    "                'placebo_improvement': placebo_improvement,\n",
    "                'difference': active_improvement - placebo_improvement,\n",
    "                'p_value': t_p_value,\n",
    "                'significant': t_p_value < 0.05\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def safety_analysis(self, trial_data):\n",
    "        \"\"\"Perform regulatory-standard safety analysis\"\"\"\n",
    "        \n",
    "        active_group = trial_data[trial_data['treatment_arm'] == 'Active']\n",
    "        placebo_group = trial_data[trial_data['treatment_arm'] == 'Placebo']\n",
    "        \n",
    "        # Adverse event rates\n",
    "        safety_results = {\n",
    "            'adverse_events': {\n",
    "                'active_rate': active_group['adverse_event'].mean(),\n",
    "                'placebo_rate': placebo_group['adverse_event'].mean(),\n",
    "                'active_count': active_group['adverse_event'].sum(),\n",
    "                'placebo_count': placebo_group['adverse_event'].sum()\n",
    "            },\n",
    "            'serious_adverse_events': {\n",
    "                'active_rate': active_group['serious_ae'].mean(),\n",
    "                'placebo_rate': placebo_group['serious_ae'].mean(),\n",
    "                'active_count': active_group['serious_ae'].sum(),\n",
    "                'placebo_count': placebo_group['serious_ae'].sum()\n",
    "            },\n",
    "            'discontinuations': {\n",
    "                'active_rate': 1 - active_group['completed_study'].mean(),\n",
    "                'placebo_rate': 1 - placebo_group['completed_study'].mean()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Risk-benefit assessment\n",
    "        efficacy_benefit = active_group['response'].mean() - placebo_group['response'].mean()\n",
    "        safety_risk = active_group['adverse_event'].mean() - placebo_group['adverse_event'].mean()\n",
    "        \n",
    "        # Number needed to treat and harm\n",
    "        nnt = 1 / efficacy_benefit if efficacy_benefit > 0 else np.inf\n",
    "        nnh = 1 / safety_risk if safety_risk > 0 else np.inf\n",
    "        \n",
    "        safety_results['risk_benefit'] = {\n",
    "            'efficacy_benefit': efficacy_benefit,\n",
    "            'safety_risk': safety_risk,\n",
    "            'nnt': nnt,\n",
    "            'nnh': nnh,\n",
    "            'benefit_risk_ratio': efficacy_benefit / safety_risk if safety_risk > 0 else np.inf\n",
    "        }\n",
    "        \n",
    "        return safety_results\n",
    "    \n",
    "    def regulatory_submission_summary(self, efficacy_results, safety_results, trial_data):\n",
    "        \"\"\"Generate regulatory submission summary\"\"\"\n",
    "        \n",
    "        total_patients = len(trial_data)\n",
    "        active_patients = len(trial_data[trial_data['treatment_arm'] == 'Active'])\n",
    "        \n",
    "        print(\"=== REGULATORY SUBMISSION SUMMARY ===\")\n",
    "        print(f\"\\nSTUDY OVERVIEW:\")\n",
    "        print(f\"Total patients enrolled: {total_patients}\")\n",
    "        print(f\"Active treatment: {active_patients}\")\n",
    "        print(f\"Placebo: {total_patients - active_patients}\")\n",
    "        \n",
    "        print(f\"\\nPRIMARY EFFICACY ENDPOINT:\")\n",
    "        pe = efficacy_results['primary_endpoint']\n",
    "        print(f\"Active response rate: {pe['active_response_rate']:.1%} (95% CI: {pe['active_ci'][0]:.1%}-{pe['active_ci'][1]:.1%})\")\n",
    "        print(f\"Placebo response rate: {pe['placebo_response_rate']:.1%} (95% CI: {pe['placebo_ci'][0]:.1%}-{pe['placebo_ci'][1]:.1%})\")\n",
    "        print(f\"Treatment difference: {pe['difference']:.1%}\")\n",
    "        print(f\"P-value: {pe['p_value']:.4f}\")\n",
    "        print(f\"Statistical significance: {'YES' if pe['significant'] else 'NO'}\")\n",
    "        \n",
    "        print(f\"\\nSECONDARY EFFICACY ENDPOINT:\")\n",
    "        se = efficacy_results['secondary_endpoint']\n",
    "        print(f\"Mean improvement - Active: {se['active_improvement']:.2f}\")\n",
    "        print(f\"Mean improvement - Placebo: {se['placebo_improvement']:.2f}\")\n",
    "        print(f\"Treatment difference: {se['difference']:.2f}\")\n",
    "        print(f\"P-value: {se['p_value']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nSAFETY PROFILE:\")\n",
    "        ae = safety_results['adverse_events']\n",
    "        sae = safety_results['serious_adverse_events']\n",
    "        disc = safety_results['discontinuations']\n",
    "        \n",
    "        print(f\"Adverse events - Active: {ae['active_rate']:.1%} ({ae['active_count']} patients)\")\n",
    "        print(f\"Adverse events - Placebo: {ae['placebo_rate']:.1%} ({ae['placebo_count']} patients)\")\n",
    "        print(f\"Serious AEs - Active: {sae['active_rate']:.1%} ({sae['active_count']} patients)\")\n",
    "        print(f\"Serious AEs - Placebo: {sae['placebo_rate']:.1%} ({sae['placebo_count']} patients)\")\n",
    "        print(f\"Discontinuation rate - Active: {disc['active_rate']:.1%}\")\n",
    "        print(f\"Discontinuation rate - Placebo: {disc['placebo_rate']:.1%}\")\n",
    "        \n",
    "        print(f\"\\nRISK-BENEFIT ASSESSMENT:\")\n",
    "        rb = safety_results['risk_benefit']\n",
    "        print(f\"Number needed to treat (NNT): {rb['nnt']:.1f}\")\n",
    "        print(f\"Number needed to harm (NNH): {rb['nnh']:.1f}\")\n",
    "        print(f\"Benefit-risk ratio: {rb['benefit_risk_ratio']:.2f}\")\n",
    "        \n",
    "        # Regulatory decision framework\n",
    "        approval_criteria = {\n",
    "            'efficacy_significant': pe['significant'],\n",
    "            'clinically_meaningful': pe['difference'] > 0.15,\n",
    "            'acceptable_safety': ae['active_rate'] < 0.25,\n",
    "            'positive_benefit_risk': rb['benefit_risk_ratio'] > 2.0\n",
    "        }\n",
    "        \n",
    "        meets_criteria = sum(approval_criteria.values())\n",
    "        total_criteria = len(approval_criteria)\n",
    "        \n",
    "        print(f\"\\nREGULATORY ASSESSMENT:\")\n",
    "        for criterion, met in approval_criteria.items():\n",
    "            print(f\"{criterion}: {'PASS' if met else 'FAIL'}\")\n",
    "        \n",
    "        print(f\"\\nOVERALL RECOMMENDATION:\")\n",
    "        if meets_criteria >= 3:\n",
    "            recommendation = \"APPROVAL RECOMMENDED\"\n",
    "        elif meets_criteria >= 2:\n",
    "            recommendation = \"CONDITIONAL APPROVAL - Additional data needed\"\n",
    "        else:\n",
    "            recommendation = \"APPROVAL NOT RECOMMENDED\"\n",
    "            \n",
    "        print(f\"{recommendation} ({meets_criteria}/{total_criteria} criteria met)\")\n",
    "        \n",
    "        return {\n",
    "            'approval_criteria': approval_criteria,\n",
    "            'criteria_met': meets_criteria,\n",
    "            'recommendation': recommendation\n",
    "        }\n",
    "\n",
    "# Task 4 Implementation\n",
    "print(\"\\n=== Task 4: Regulatory Compliance Modeling ===\")\n",
    "\n",
    "# Initialize regulatory modeling\n",
    "regulatory = RegulatoryModeling()\n",
    "\n",
    "# Generate clinical trial data\n",
    "print(\"\\n1. Generating clinical trial dataset...\")\n",
    "trial_data = regulatory.generate_clinical_trial_data(400)\n",
    "print(f\"Generated trial data for {len(trial_data)} patients\")\n",
    "print(\"\\nTrial data preview:\")\n",
    "print(trial_data[['patient_id', 'age', 'treatment_arm', 'baseline_severity', 'response', 'adverse_event']].head())\n",
    "\n",
    "print(\"\\n2. Performing efficacy analysis...\")\n",
    "efficacy_results = regulatory.efficacy_analysis(trial_data)\n",
    "\n",
    "print(\"\\n3. Performing safety analysis...\")\n",
    "safety_results = regulatory.safety_analysis(trial_data)\n",
    "\n",
    "print(\"\\n4. Generating regulatory submission summary...\")\n",
    "submission = regulatory.regulatory_submission_summary(efficacy_results, safety_results, trial_data)\n",
    "\n",
    "# Update final progress\n",
    "task_scores['task_4_regulatory_modeling'] = 25\n",
    "skills_developed['regulatory_compliance'] = True\n",
    "tasks_completed += 1\n",
    "current_score += 25\n",
    "\n",
    "print(f\"\\nâœ“ Task 4 completed! Score: 25/25\")\n",
    "print(f\"Progress: {tasks_completed}/4 tasks completed\")\n",
    "print(f\"Current Score: {current_score}/{total_points} points\")\n",
    "\n",
    "# Week 9 Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"WEEK 9 CHECKPOINT COMPLETED!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final Score: {current_score}/{total_points} points\")\n",
    "print(f\"\\nTasks Completed:\")\n",
    "for task, score in task_scores.items():\n",
    "    print(f\"  {task}: {score}/25 points\")\n",
    "    \n",
    "print(f\"\\nSkills Developed:\")\n",
    "for skill, developed in skills_developed.items():\n",
    "    print(f\"  {skill}: {'âœ“' if developed else 'âœ—'}\")\n",
    "    \n",
    "print(f\"\\nNext Steps: Proceed to Week 10 - Integration and Validation\")"
   ]
  }
 ],
 "metadata": {
  "chemml": {
   "integrated": true,
   "integration_date": "2025-06-15T23:50:25.013047",
   "version": "1.0"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
