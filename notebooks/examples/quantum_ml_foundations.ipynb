{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2869a83c",
   "metadata": {},
   "source": [
    "# Day 5 Module 1: Core Quantum ML Foundations 🧬\n",
    "\n",
    "## **Welcome to Day 5 - Quantum Machine Learning Integration!**\n",
    "\n",
    "This is **Module 1 of 3** for Day 5, focusing on fundamental quantum ML concepts and the QM9 dataset.\n",
    "\n",
    "### **📍 Module Navigation:**\n",
    "- **Current**: Module 1 - Core Quantum ML Foundations (this notebook)\n",
    "- **Next**: Module 2 - Advanced Quantum ML Architectures\n",
    "- **Final**: Module 3 - Production Integration & Applications\n",
    "\n",
    "### **Module 1 Learning Objectives:**\n",
    "- Master the QM9 dataset and quantum property prediction\n",
    "- Implement basic SchNet architecture foundations\n",
    "- Understand quantum feature engineering principles\n",
    "- Complete foundational assessment checkpoints\n",
    "\n",
    "### **Prerequisites from Previous Days:**\n",
    "- Day 1: ML & Cheminformatics foundations\n",
    "- Day 2: Deep learning for molecules\n",
    "- Day 3: Molecular analysis pipelines\n",
    "- Day 4: Quantum chemistry calculations\n",
    "\n",
    "---\n",
    "\n",
    "## **Section 1: QM9 Dataset Mastery & Quantum Feature Engineering** 🧬\n",
    "\n",
    "Let's start by mastering the QM9 dataset - one of the most important quantum ML benchmarks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for Quantum ML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core scientific computing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "# Chemistry and quantum computing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, rdMolDescriptors\n",
    "import deepchem as dc\n",
    "from ase import Atoms\n",
    "from ase.io import read, write\n",
    "\n",
    "# ML and optimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "\n",
    "# Visualization and analysis\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import joblib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"🎯 Quantum ML Integration Environment Ready!\")\n",
    "print(f\"📊 PyTorch version: {torch.__version__}\")\n",
    "print(f\"🧪 RDKit available: {Chem is not None}\")\n",
    "print(f\"🔬 DeepChem version: {dc.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎓 **MODULE 1 ASSESSMENT FRAMEWORK INITIALIZATION**\n",
    "\n",
    "print(\"🎓 MODULE 1 ASSESSMENT FRAMEWORK INITIALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    from assessment_framework import create_assessment, create_widget, create_dashboard\n",
    "    print(\"✅ Assessment framework loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ Assessment framework not found. Please ensure assessment_framework.py is available.\")\n",
    "    print(\"📁 Expected location: same directory as this notebook\")\n",
    "    # Create a basic assessment object for fallback\n",
    "    class BasicAssessment:\n",
    "        def start_section(self, section): pass\n",
    "        def end_section(self, section): pass\n",
    "        def record_activity(self, activity, result, metadata=None): pass\n",
    "        def get_progress_summary(self): return {\"overall_score\": 0.0, \"section_scores\": {}}\n",
    "        def get_comprehensive_report(self): return {\"activities\": []}\n",
    "        def save_final_report(self, filename): pass\n",
    "    \n",
    "    class BasicWidget:\n",
    "        def display(self): print(\"📋 Assessment widget would appear here\")\n",
    "    \n",
    "    def create_assessment(student_id, day=5, track=\"quantum_ml\"):\n",
    "        return BasicAssessment()\n",
    "    \n",
    "    def create_widget(assessment, section, concepts, activities):\n",
    "        return BasicWidget()\n",
    "    \n",
    "    def create_dashboard(assessment):\n",
    "        return BasicWidget()\n",
    "\n",
    "# Student Information Collection\n",
    "print(\"\\n📝 Student Assessment Setup:\")\n",
    "student_id = input(\"Enter your student ID: \").strip()\n",
    "if not student_id:\n",
    "    student_id = f\"student_day5_mod1_{np.random.randint(1000, 9999)}\"\n",
    "    print(f\"Generated ID: {student_id}\")\n",
    "\n",
    "# Track Selection for Day 5 Module 1\n",
    "print(\"\\n🎯 Module 1 Focus: Core Quantum ML Foundations\")\n",
    "print(\"   • QM9 dataset mastery\")\n",
    "print(\"   • Quantum feature engineering\")\n",
    "print(\"   • Basic SchNet concepts\")\n",
    "\n",
    "# Initialize Assessment System\n",
    "try:\n",
    "    assessment = create_assessment(student_id=student_id, day=5, track=\"quantum_ml_foundations\")\n",
    "    print(f\"✅ Module 1 assessment initialized\")\n",
    "    print(f\"👤 Student ID: {student_id}\")\n",
    "    \n",
    "    # Start Module 1 assessment\n",
    "    assessment.start_section(\"day_5_module_1_foundations\")\n",
    "    print(\"\\n🎯 Day 5 Module 1 Assessment: Core Quantum ML Foundations\")\n",
    "    print(\"📊 Progress tracking enabled - All activities will be recorded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Assessment initialization warning: {e}\")\n",
    "    assessment = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🚀 Ready to begin Module 1: Core Quantum ML Foundations!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c292d37",
   "metadata": {},
   "source": [
    "### **1.1 QM9 Dataset Handler - Professional Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a66053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9DatasetHandler:\n",
    "    \"\"\"\n",
    "    Professional QM9 dataset handler with advanced preprocessing capabilities.\n",
    "    \n",
    "    The QM9 dataset contains ~134k small organic molecules with quantum chemical properties\n",
    "    computed at the B3LYP/6-31G(2df,p) level of theory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: str = \"./qm9_cache\"):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # QM9 property definitions with units and descriptions\n",
    "        self.qm9_properties = {\n",
    "            'mu': {'name': 'Dipole moment', 'unit': 'Debye', 'index': 0},\n",
    "            'alpha': {'name': 'Polarizability', 'unit': 'Bohr^3', 'index': 1},\n",
    "            'homo': {'name': 'HOMO energy', 'unit': 'Hartree', 'index': 2},\n",
    "            'lumo': {'name': 'LUMO energy', 'unit': 'Hartree', 'index': 3},\n",
    "            'gap': {'name': 'HOMO-LUMO gap', 'unit': 'Hartree', 'index': 4},\n",
    "            'r2': {'name': 'Electronic spatial extent', 'unit': 'Bohr^2', 'index': 5},\n",
    "            'zpve': {'name': 'Zero-point vibrational energy', 'unit': 'Hartree', 'index': 6},\n",
    "            'u0': {'name': 'Internal energy at 0K', 'unit': 'Hartree', 'index': 7},\n",
    "            'u298': {'name': 'Internal energy at 298K', 'unit': 'Hartree', 'index': 8},\n",
    "            'h298': {'name': 'Enthalpy at 298K', 'unit': 'Hartree', 'index': 9},\n",
    "            'g298': {'name': 'Free energy at 298K', 'unit': 'Hartree', 'index': 10},\n",
    "            'cv': {'name': 'Heat capacity at 298K', 'unit': 'cal/(mol*K)', 'index': 11}\n",
    "        }\n",
    "        \n",
    "        self.data = None\n",
    "        self.molecular_graphs = []\n",
    "        self.statistics = {}\n",
    "        \n",
    "    def load_qm9_dataset(self, subset_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load and preprocess QM9 dataset with caching.\n",
    "        \"\"\"\n",
    "        cache_file = self.cache_dir / f\"qm9_processed_{subset_size or 'full'}.pkl\"\n",
    "        \n",
    "        if cache_file.exists():\n",
    "            logger.info(f\"Loading cached QM9 data from {cache_file}\")\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                self.data = pickle.load(f)\n",
    "            return self.data\n",
    "        \n",
    "        logger.info(\"Loading QM9 dataset from DeepChem...\")\n",
    "        try:\n",
    "            # Load QM9 dataset using DeepChem\n",
    "            qm9_loader = dc.molnet.load_qm9(featurizer='ECFP', split='random')\n",
    "            train, valid, test = qm9_loader[0]\n",
    "            \n",
    "            # Combine all data\n",
    "            all_smiles = np.concatenate([train[0], valid[0], test[0]])\n",
    "            all_properties = np.concatenate([train[1], valid[1], test[1]])\n",
    "            \n",
    "            # Create DataFrame\n",
    "            property_names = list(self.qm9_properties.keys())\n",
    "            \n",
    "            data_dict = {'smiles': all_smiles}\n",
    "            for i, prop in enumerate(property_names):\n",
    "                data_dict[prop] = all_properties[:, i]\n",
    "            \n",
    "            self.data = pd.DataFrame(data_dict)\n",
    "            \n",
    "            # Apply subset if requested\n",
    "            if subset_size and subset_size < len(self.data):\n",
    "                self.data = self.data.sample(n=subset_size, random_state=42).reset_index(drop=True)\n",
    "            \n",
    "            # Cache the processed data\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(self.data, f)\n",
    "            \n",
    "            logger.info(f\"QM9 dataset loaded: {len(self.data)} molecules\")\n",
    "            return self.data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading QM9 dataset: {e}\")\n",
    "            # Fallback: create synthetic QM9-like data for demonstration\n",
    "            return self._create_synthetic_qm9(subset_size or 1000)\n",
    "    \n",
    "    def _create_synthetic_qm9(self, n_samples: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create synthetic QM9-like data for demonstration purposes.\n",
    "        \"\"\"\n",
    "        logger.warning(\"Creating synthetic QM9-like data for demonstration\")\n",
    "        \n",
    "        # Generate simple organic molecules\n",
    "        simple_smiles = [\n",
    "            'C', 'CC', 'CCC', 'CCCC', 'CCCCC',  # Alkanes\n",
    "            'C=C', 'CC=C', 'C=CC=C',  # Alkenes\n",
    "            'C#C', 'CC#C',  # Alkynes\n",
    "            'c1ccccc1', 'Cc1ccccc1',  # Aromatics\n",
    "            'CO', 'CCO', 'CCCO',  # Alcohols\n",
    "            'C=O', 'CC=O', 'CCC=O',  # Aldehydes/Ketones\n",
    "            'CN', 'CCN', 'CCCN',  # Amines\n",
    "        ]\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        smiles_list = np.random.choice(simple_smiles, n_samples)\n",
    "        \n",
    "        # Generate synthetic properties with realistic ranges\n",
    "        data_dict = {'smiles': smiles_list}\n",
    "        \n",
    "        # Realistic property ranges based on QM9 statistics\n",
    "        property_ranges = {\n",
    "            'mu': (0, 5),  # Debye\n",
    "            'alpha': (10, 100),  # Bohr^3\n",
    "            'homo': (-0.3, -0.1),  # Hartree\n",
    "            'lumo': (-0.1, 0.1),  # Hartree\n",
    "            'gap': (0.05, 0.3),  # Hartree\n",
    "            'r2': (20, 200),  # Bohr^2\n",
    "            'zpve': (0.01, 0.3),  # Hartree\n",
    "            'u0': (-500, -100),  # Hartree\n",
    "            'u298': (-500, -100),  # Hartree\n",
    "            'h298': (-500, -100),  # Hartree\n",
    "            'g298': (-500, -100),  # Hartree\n",
    "            'cv': (5, 50)  # cal/(mol*K)\n",
    "        }\n",
    "        \n",
    "        for prop, (low, high) in property_ranges.items():\n",
    "            data_dict[prop] = np.random.uniform(low, high, n_samples)\n",
    "        \n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "        return self.data\n",
    "    \n",
    "    def compute_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Compute comprehensive statistics for QM9 properties.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data loaded. Call load_qm9_dataset first.\")\n",
    "        \n",
    "        stats = {}\n",
    "        \n",
    "        for prop in self.qm9_properties.keys():\n",
    "            if prop in self.data.columns:\n",
    "                values = self.data[prop].values\n",
    "                stats[prop] = {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values),\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values),\n",
    "                    'median': np.median(values),\n",
    "                    'q25': np.percentile(values, 25),\n",
    "                    'q75': np.percentile(values, 75),\n",
    "                    'skewness': self._compute_skewness(values),\n",
    "                    'kurtosis': self._compute_kurtosis(values)\n",
    "                }\n",
    "        \n",
    "        self.statistics = stats\n",
    "        return stats\n",
    "    \n",
    "    def _compute_skewness(self, values: np.ndarray) -> float:\n",
    "        \"\"\"Compute skewness of the distribution.\"\"\"\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        return np.mean(((values - mean) / std) ** 3)\n",
    "    \n",
    "    def _compute_kurtosis(self, values: np.ndarray) -> float:\n",
    "        \"\"\"Compute kurtosis of the distribution.\"\"\"\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        return np.mean(((values - mean) / std) ** 4) - 3\n",
    "    \n",
    "    def visualize_property_distributions(self, properties: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Create comprehensive visualization of QM9 property distributions.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data loaded. Call load_qm9_dataset first.\")\n",
    "        \n",
    "        if properties is None:\n",
    "            properties = list(self.qm9_properties.keys())\n",
    "        \n",
    "        # Filter available properties\n",
    "        available_props = [p for p in properties if p in self.data.columns]\n",
    "        \n",
    "        n_props = len(available_props)\n",
    "        n_cols = 3\n",
    "        n_rows = (n_props + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=n_rows, cols=n_cols,\n",
    "            subplot_titles=[f\"{prop} ({self.qm9_properties[prop]['unit']})\" \n",
    "                          for prop in available_props],\n",
    "            vertical_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        for i, prop in enumerate(available_props):\n",
    "            row = i // n_cols + 1\n",
    "            col = i % n_cols + 1\n",
    "            \n",
    "            values = self.data[prop].values\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=values,\n",
    "                    name=prop,\n",
    "                    nbinsx=50,\n",
    "                    showlegend=False,\n",
    "                    marker_color=px.colors.qualitative.Set3[i % len(px.colors.qualitative.Set3)]\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"QM9 Property Distributions\",\n",
    "            height=300 * n_rows,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Initialize QM9 handler\n",
    "qm9_handler = QM9DatasetHandler()\n",
    "print(\"\\n🎯 QM9 Dataset Handler initialized!\")\n",
    "print(\"📊 Ready to load and analyze quantum chemical properties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f53d6",
   "metadata": {},
   "source": [
    "### **1.2 Load and Explore QM9 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b7136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QM9 dataset (using subset for faster processing)\n",
    "print(\"Loading QM9 dataset...\")\n",
    "qm9_data = qm9_handler.load_qm9_dataset(subset_size=2000)  # Start with 2k molecules for Module 1\n",
    "\n",
    "print(f\"\\n📊 QM9 Dataset Overview:\")\n",
    "print(f\"   • Total molecules: {len(qm9_data)}\")\n",
    "print(f\"   • Properties: {len(qm9_handler.qm9_properties)}\")\n",
    "print(f\"   • Data shape: {qm9_data.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n🔍 Sample data:\")\n",
    "display(qm9_data.head())\n",
    "\n",
    "# Compute and display statistics\n",
    "print(\"\\nComputing property statistics...\")\n",
    "stats = qm9_handler.compute_statistics()\n",
    "\n",
    "# Create statistics summary table\n",
    "stats_df = pd.DataFrame({\n",
    "    prop: {\n",
    "        'Mean': f\"{data['mean']:.4f}\",\n",
    "        'Std': f\"{data['std']:.4f}\",\n",
    "        'Min': f\"{data['min']:.4f}\",\n",
    "        'Max': f\"{data['max']:.4f}\",\n",
    "        'Unit': qm9_handler.qm9_properties[prop]['unit']\n",
    "    }\n",
    "    for prop, data in stats.items()\n",
    "}).T\n",
    "\n",
    "print(\"\\n📈 QM9 Property Statistics:\")\n",
    "display(stats_df)\n",
    "\n",
    "# Visualize property distributions\n",
    "print(\"\\nGenerating property distribution plots...\")\n",
    "fig = qm9_handler.visualize_property_distributions(['mu', 'alpha', 'homo', 'lumo', 'gap', 'cv'])\n",
    "\n",
    "print(\"\\n✅ QM9 dataset successfully loaded and analyzed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590726b",
   "metadata": {},
   "source": [
    "### **1.3 Basic Quantum Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5199aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQuantumFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Basic quantum feature engineering for Module 1 - focusing on core concepts.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_cache = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "    def extract_basic_features(self, smiles_list: List[str]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Extract basic molecular features for quantum property prediction.\n",
    "        \"\"\"\n",
    "        features = {\n",
    "            'constitutional': [],\n",
    "            'electronic': [],\n",
    "            'aromatic': []\n",
    "        }\n",
    "        \n",
    "        valid_molecules = []\n",
    "        \n",
    "        for smiles in smiles_list:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            valid_molecules.append(smiles)\n",
    "            \n",
    "            # Constitutional descriptors (basic structure)\n",
    "            const_features = [\n",
    "                mol.GetNumAtoms(),\n",
    "                mol.GetNumBonds(),\n",
    "                mol.GetNumHeavyAtoms(),\n",
    "                Descriptors.MolWt(mol),\n",
    "                Descriptors.NumHeteroatoms(mol),\n",
    "                Descriptors.NumRotatableBonds(mol)\n",
    "            ]\n",
    "            features['constitutional'].append(const_features)\n",
    "            \n",
    "            # Electronic descriptors (quantum-relevant)\n",
    "            elec_features = [\n",
    "                Descriptors.NumValenceElectrons(mol),\n",
    "                sum(1 for atom in mol.GetAtoms() if atom.GetAtomicNum() == 6),  # Carbon count\n",
    "                sum(1 for atom in mol.GetAtoms() if atom.GetAtomicNum() == 7),  # Nitrogen count\n",
    "                sum(1 for atom in mol.GetAtoms() if atom.GetAtomicNum() == 8),  # Oxygen count\n",
    "            ]\n",
    "            features['electronic'].append(elec_features)\n",
    "            \n",
    "            # Aromatic descriptors (important for HOMO/LUMO)\n",
    "            # Calculate FractionCsp3 manually if not available\n",
    "            try:\n",
    "                fraction_csp3 = Descriptors.FractionCsp3(mol) if Descriptors.FractionCsp3(mol) is not None else 0.0\n",
    "            except AttributeError:\n",
    "                # Manual calculation: ratio of sp3 carbons to total carbons\n",
    "                sp3_carbons = sum(1 for atom in mol.GetAtoms() \n",
    "                                if atom.GetAtomicNum() == 6 and atom.GetHybridization() == Chem.HybridizationType.SP3)\n",
    "                total_carbons = sum(1 for atom in mol.GetAtoms() if atom.GetAtomicNum() == 6)\n",
    "                fraction_csp3 = sp3_carbons / total_carbons if total_carbons > 0 else 0.0\n",
    "            \n",
    "            aromatic_features = [\n",
    "                Descriptors.NumAromaticRings(mol),\n",
    "                sum(1 for atom in mol.GetAtoms() if atom.GetIsAromatic()),\n",
    "                sum(1 for bond in mol.GetBonds() if bond.GetIsAromatic()),\n",
    "                fraction_csp3\n",
    "            ]\n",
    "            features['aromatic'].append(aromatic_features)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        for key in features:\n",
    "            if features[key]:\n",
    "                features[key] = np.array(features[key])\n",
    "            else:\n",
    "                features[key] = np.array([]).reshape(0, 0)\n",
    "        \n",
    "        self.valid_molecules = valid_molecules\n",
    "        return features\n",
    "    \n",
    "    def create_feature_matrix(self, features_dict: Dict[str, np.ndarray]) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Combine all feature types into a single matrix.\n",
    "        \"\"\"\n",
    "        feature_arrays = []\n",
    "        feature_names = []\n",
    "        \n",
    "        # Constitutional features\n",
    "        if features_dict['constitutional'].size > 0:\n",
    "            feature_arrays.append(features_dict['constitutional'])\n",
    "            feature_names.extend(['num_atoms', 'num_bonds', 'num_heavy_atoms', \n",
    "                                'mol_weight', 'num_heteroatoms', 'num_rotatable_bonds'])\n",
    "        \n",
    "        # Electronic features\n",
    "        if features_dict['electronic'].size > 0:\n",
    "            feature_arrays.append(features_dict['electronic'])\n",
    "            feature_names.extend(['num_valence_electrons', 'carbon_count', \n",
    "                                'nitrogen_count', 'oxygen_count'])\n",
    "        \n",
    "        # Aromatic features\n",
    "        if features_dict['aromatic'].size > 0:\n",
    "            feature_arrays.append(features_dict['aromatic'])\n",
    "            feature_names.extend(['num_aromatic_rings', 'aromatic_atoms', \n",
    "                                'aromatic_bonds', 'fraction_csp3'])\n",
    "        \n",
    "        if feature_arrays:\n",
    "            combined_features = np.hstack(feature_arrays)\n",
    "        else:\n",
    "            combined_features = np.array([]).reshape(0, 0)\n",
    "        \n",
    "        return combined_features, feature_names\n",
    "    \n",
    "    def scale_features(self, features: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Scale features using standard scaling.\n",
    "        \"\"\"\n",
    "        if 'standard' not in self.scalers:\n",
    "            self.scalers['standard'] = StandardScaler()\n",
    "        \n",
    "        scaler = self.scalers['standard']\n",
    "        \n",
    "        if not hasattr(scaler, 'mean_'):\n",
    "            scaled_features = scaler.fit_transform(features)\n",
    "        else:\n",
    "            scaled_features = scaler.transform(features)\n",
    "        \n",
    "        return scaled_features\n",
    "\n",
    "# Initialize basic feature engineer\n",
    "basic_feature_engineer = BasicQuantumFeatureEngineer()\n",
    "print(\"\\n🎯 Basic Quantum Feature Engineer initialized!\")\n",
    "print(\"🔬 Ready to extract core molecular features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02257829",
   "metadata": {},
   "source": [
    "### **1.4 Extract Features and Build Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385046b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract basic molecular features\n",
    "print(\"Extracting basic molecular features...\")\n",
    "smiles_list = qm9_data['smiles'].tolist()\n",
    "\n",
    "start_time = time.time()\n",
    "basic_features_dict = basic_feature_engineer.extract_basic_features(smiles_list)\n",
    "feature_extraction_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n⏱️ Feature extraction completed in {feature_extraction_time:.2f} seconds\")\n",
    "\n",
    "# Display feature statistics\n",
    "for feature_type, features in basic_features_dict.items():\n",
    "    if features.size > 0:\n",
    "        print(f\"   • {feature_type}: {features.shape[1]} features, {features.shape[0]} molecules\")\n",
    "\n",
    "# Create combined feature matrix\n",
    "basic_feature_matrix, basic_feature_names = basic_feature_engineer.create_feature_matrix(basic_features_dict)\n",
    "\n",
    "print(f\"\\n📊 Basic Feature Matrix:\")\n",
    "print(f\"   • Shape: {basic_feature_matrix.shape}\")\n",
    "print(f\"   • Features: {basic_feature_names}\")\n",
    "\n",
    "# Scale features\n",
    "print(\"\\nScaling features...\")\n",
    "scaled_basic_features = basic_feature_engineer.scale_features(basic_feature_matrix)\n",
    "\n",
    "# Record the feature extraction in assessment\n",
    "if assessment:\n",
    "    assessment.record_activity(\n",
    "        \"quantum_feature_engineering\", \n",
    "        \"completed\",\n",
    "        {\n",
    "            \"feature_types\": list(basic_features_dict.keys()),\n",
    "            \"total_features\": len(basic_feature_names),\n",
    "            \"molecules_processed\": len(basic_feature_engineer.valid_molecules),\n",
    "            \"processing_time\": feature_extraction_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"✅ Basic features extracted and scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ba85a",
   "metadata": {},
   "source": [
    "### **1.5 Baseline Quantum Property Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align QM9 data with valid molecules\n",
    "valid_indices = [i for i, smiles in enumerate(qm9_data['smiles']) \n",
    "                if smiles in basic_feature_engineer.valid_molecules]\n",
    "aligned_qm9_data = qm9_data.iloc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Aligned dataset: {len(aligned_qm9_data)} molecules\")\n",
    "\n",
    "# Focus on key quantum properties for Module 1\n",
    "key_properties = ['homo', 'lumo', 'gap', 'mu']\n",
    "available_properties = [p for p in key_properties if p in aligned_qm9_data.columns]\n",
    "\n",
    "print(f\"\\n🎯 Predicting key quantum properties: {available_properties}\")\n",
    "\n",
    "# Train simple baseline models\n",
    "baseline_results = {}\n",
    "\n",
    "for prop in available_properties:\n",
    "    print(f\"\\n📊 Training baseline model for {prop}...\")\n",
    "    \n",
    "    # Get target values\n",
    "    y_values = aligned_qm9_data[prop].values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_basic_features, y_values, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=50,  # Reduced for faster training in Module 1\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(y_test, rf_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "    r2 = r2_score(y_test, rf_pred)\n",
    "    \n",
    "    baseline_results[prop] = {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'model': rf_model,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': rf_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"   • MAE: {mae:.4f}\")\n",
    "    print(f\"   • RMSE: {rmse:.4f}\")\n",
    "    print(f\"   • R²: {r2:.4f}\")\n",
    "\n",
    "# Create simple prediction plot\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=available_properties[:4],\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "for i, prop in enumerate(available_properties[:4]):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    \n",
    "    results = baseline_results[prop]\n",
    "    y_test = results['y_test']\n",
    "    y_pred = results['y_pred']\n",
    "    \n",
    "    # Scatter plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_test,\n",
    "            y=y_pred,\n",
    "            mode='markers',\n",
    "            name=prop,\n",
    "            showlegend=False,\n",
    "            marker=dict(size=4, opacity=0.6)\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_val, max_val],\n",
    "            y=[min_val, max_val],\n",
    "            mode='lines',\n",
    "            line=dict(dash='dash', color='red'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Actual\", row=row, col=col)\n",
    "    fig.update_yaxes(title_text=\"Predicted\", row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Module 1 Baseline Model Performance\",\n",
    "    height=600,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n📊 Module 1 Baseline Results Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for prop, results in baseline_results.items():\n",
    "    prop_info = qm9_handler.qm9_properties[prop]\n",
    "    print(f\"{prop_info['name']:25} | MAE: {results['mae']:.4f} | R²: {results['r2']:.3f}\")\n",
    "\n",
    "print(\"\\n✅ Module 1 Complete: Core Quantum ML Foundations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc486f0f",
   "metadata": {},
   "source": [
    "## **📋 Module 1 Assessment & Completion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc68e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 MODULE 1 CHECKPOINT ASSESSMENT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 MODULE 1 CHECKPOINT ASSESSMENT: Core Quantum ML Foundations\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if assessment:\n",
    "    # Record module completion\n",
    "    assessment.record_activity(\n",
    "        \"module_1_completion\", \n",
    "        \"completed\",\n",
    "        {\n",
    "            \"module\": \"Core Quantum ML Foundations\", \n",
    "            \"dataset_size\": len(aligned_qm9_data),\n",
    "            \"features_extracted\": len(basic_feature_names),\n",
    "            \"properties_modeled\": len(baseline_results),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create assessment widget for Module 1\n",
    "module1_widget = create_widget(\n",
    "    assessment=assessment,\n",
    "    section=\"Module 1: Core Quantum ML Foundations\",\n",
    "    concepts=[\n",
    "        \"QM9 dataset structure and loading\",\n",
    "        \"Quantum chemical property understanding (HOMO, LUMO, gap, dipole)\", \n",
    "        \"Basic molecular feature extraction\",\n",
    "        \"Feature scaling and preprocessing\",\n",
    "        \"Baseline model training and evaluation\",\n",
    "        \"Performance metrics interpretation\"\n",
    "    ],\n",
    "    activities=[\n",
    "        \"Successfully loaded QM9 dataset subset\",\n",
    "        \"Analyzed quantum chemical property distributions\",\n",
    "        \"Implemented basic feature engineering pipeline\",\n",
    "        \"Created and evaluated baseline prediction models\",\n",
    "        \"Interpreted model performance for quantum properties\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the interactive assessment\n",
    "module1_widget.display()\n",
    "\n",
    "# Progress tracking\n",
    "if assessment:\n",
    "    progress = assessment.get_progress_summary()\n",
    "    print(f\"\\n📊 Module 1 Progress: {progress['overall_score']:.1f}%\")\n",
    "\n",
    "print(\"\\n🎯 Module 1 Complete! Ready for Module 2: Advanced Quantum ML Architectures\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📍 NEXT STEPS:\")\n",
    "print(\"   📖 Continue to: day_05_module_2_advanced.ipynb\")\n",
    "print(\"   🎯 Focus: SchNet implementation and advanced architectures\")\n",
    "print(\"   💡 Build on: Foundation concepts from this module\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123fe65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
