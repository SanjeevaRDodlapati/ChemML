{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5992f022",
   "metadata": {},
   "source": [
    "# Deep Learning for Drug Discovery with DeepChem\n",
    "\n",
    "This notebook demonstrates how to use DeepChem for molecular property prediction and drug discovery tasks.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and preprocess molecular datasets\n",
    "- Create molecular featurizations\n",
    "- Build and train deep learning models\n",
    "- Evaluate model performance for drug discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aedc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"DeepChem version: {dc.__version__}\")\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a58847f",
   "metadata": {},
   "source": [
    "## 1. Loading and Exploring Molecular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c193f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset with SMILES and properties\n",
    "# In practice, you would load this from a file or database\n",
    "sample_data = {\n",
    "    'smiles': [\n",
    "        'CCO',  # Ethanol\n",
    "        'CC(=O)O',  # Acetic acid\n",
    "        'c1ccccc1',  # Benzene\n",
    "        'CC(=O)Nc1ccc(O)cc1',  # Paracetamol\n",
    "        'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O',  # Ibuprofen\n",
    "        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Caffeine\n",
    "        'CC(C)NCC(C1=CC(=C(C=C1)O)CO)O',  # Salbutamol\n",
    "        'CC1=CC=C(C=C1)C2=CC=C(C=C2)C',  # 4,4'-Dimethylbiphenyl\n",
    "        'C1=CC=C(C=C1)C(=O)O',  # Benzoic acid\n",
    "        'CC(C)(C)C1=CC=C(C=C1)O'  # 4-tert-Butylphenol\n",
    "    ],\n",
    "    'logp': [−0.31, −0.17, 2.13, 0.46, 3.97, −0.07, 0.1, 4.79, 1.87, 3.31],  # LogP values\n",
    "    'solubility': [0.0, 0.0, -2.13, -1.46, -3.97, -0.8, -1.5, -4.79, -1.87, -3.31],  # Log solubility\n",
    "    'mw': [46.07, 60.05, 78.11, 151.16, 206.28, 194.19, 239.31, 182.26, 122.12, 150.22]  # Molecular weight\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "print(\"Sample molecular dataset:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3015f6",
   "metadata": {},
   "source": [
    "## 2. Molecular Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different featurization methods in DeepChem\n",
    "\n",
    "# 1. Circular Fingerprints (ECFP)\n",
    "ecfp_featurizer = dc.feat.CircularFingerprint(size=1024, radius=2)\n",
    "ecfp_features = ecfp_featurizer.featurize(df['smiles'])\n",
    "\n",
    "print(f\"ECFP features shape: {ecfp_features.shape}\")\n",
    "print(f\"ECFP features for first molecule: {ecfp_features[0][:10]}...\")  # First 10 features\n",
    "\n",
    "# 2. RDKit Descriptors\n",
    "rdkit_featurizer = dc.feat.RDKitDescriptors()\n",
    "rdkit_features = rdkit_featurizer.featurize(df['smiles'])\n",
    "\n",
    "print(f\"\\nRDKit descriptors shape: {rdkit_features.shape}\")\n",
    "print(f\"RDKit descriptors for first molecule: {rdkit_features[0][:5]}...\")  # First 5 descriptors\n",
    "\n",
    "# 3. Coulomb Matrix (for small molecules)\n",
    "try:\n",
    "    coulomb_featurizer = dc.feat.CoulombMatrix(max_atoms=50)\n",
    "    coulomb_features = coulomb_featurizer.featurize(df['smiles'])\n",
    "    print(f\"\\nCoulomb Matrix features shape: {coulomb_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCoulomb Matrix featurization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e273d8",
   "metadata": {},
   "source": [
    "## 3. Creating DeepChem Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepChem datasets for different properties\n",
    "\n",
    "# Dataset for LogP prediction\n",
    "logp_dataset = dc.data.NumpyDataset(\n",
    "    X=ecfp_features,\n",
    "    y=np.array(df['logp']).reshape(-1, 1),\n",
    "    ids=df['smiles']\n",
    ")\n",
    "\n",
    "# Dataset for solubility prediction\n",
    "solubility_dataset = dc.data.NumpyDataset(\n",
    "    X=ecfp_features,\n",
    "    y=np.array(df['solubility']).reshape(-1, 1),\n",
    "    ids=df['smiles']\n",
    ")\n",
    "\n",
    "print(f\"LogP dataset: {logp_dataset}\")\n",
    "print(f\"Features shape: {logp_dataset.X.shape}\")\n",
    "print(f\"Labels shape: {logp_dataset.y.shape}\")\n",
    "print(f\"Number of tasks: {logp_dataset.n_tasks}\")\n",
    "print(f\"Number of features: {logp_dataset.n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035e3a2",
   "metadata": {},
   "source": [
    "## 4. Data Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train/validation/test\n",
    "# For small datasets, we'll use a simple random split\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(\n",
    "    logp_dataset, \n",
    "    train_dir=None,\n",
    "    valid_dir=None,\n",
    "    test_dir=None,\n",
    "    frac_train=0.6,\n",
    "    frac_valid=0.2,\n",
    "    frac_test=0.2\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(valid_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "# Apply normalization\n",
    "normalizer = dc.trans.NormalizationTransformer(\n",
    "    transform_y=True, dataset=train_dataset\n",
    ")\n",
    "\n",
    "train_dataset_norm = normalizer.transform(train_dataset)\n",
    "valid_dataset_norm = normalizer.transform(valid_dataset)\n",
    "test_dataset_norm = normalizer.transform(test_dataset)\n",
    "\n",
    "print(\"\\nDatasets normalized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cebf8b",
   "metadata": {},
   "source": [
    "## 5. Building and Training Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e09bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of models\n",
    "\n",
    "# 1. Multi-layer Perceptron (MLP)\n",
    "mlp_model = dc.models.MultitaskRegressor(\n",
    "    n_tasks=1,\n",
    "    n_features=1024,  # ECFP size\n",
    "    layer_sizes=[512, 256, 128],\n",
    "    dropouts=0.2,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Training MLP model...\")\n",
    "mlp_model.fit(train_dataset_norm, nb_epoch=50)\n",
    "print(\"MLP training completed!\")\n",
    "\n",
    "# 2. Random Forest (for comparison)\n",
    "rf_model = dc.models.SklearnModel(\n",
    "    model_instance=dc.models.sklearn_models.RandomForestRegressor(\n",
    "        n_estimators=100, random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rf_model.fit(train_dataset)\n",
    "print(\"Random Forest training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da621f",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dddeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set\n",
    "metric = dc.metrics.Metric(dc.metrics.r2_score)\n",
    "\n",
    "# MLP evaluation\n",
    "mlp_train_score = mlp_model.evaluate(train_dataset_norm, [metric])\n",
    "mlp_valid_score = mlp_model.evaluate(valid_dataset_norm, [metric])\n",
    "mlp_test_score = mlp_model.evaluate(test_dataset_norm, [metric])\n",
    "\n",
    "# Random Forest evaluation\n",
    "rf_train_score = rf_model.evaluate(train_dataset, [metric])\n",
    "rf_valid_score = rf_model.evaluate(valid_dataset, [metric])\n",
    "rf_test_score = rf_model.evaluate(test_dataset, [metric])\n",
    "\n",
    "print(\"Model Performance (R² Score):\")\n",
    "print(\"\\nMLP Model:\")\n",
    "print(f\"  Train R²: {mlp_train_score['r2_score']:.3f}\")\n",
    "print(f\"  Valid R²: {mlp_valid_score['r2_score']:.3f}\")\n",
    "print(f\"  Test R²:  {mlp_test_score['r2_score']:.3f}\")\n",
    "\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "print(f\"  Train R²: {rf_train_score['r2_score']:.3f}\")\n",
    "print(f\"  Valid R²: {rf_valid_score['r2_score']:.3f}\")\n",
    "print(f\"  Test R²:  {rf_test_score['r2_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09090f",
   "metadata": {},
   "source": [
    "## 7. Making Predictions and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "mlp_predictions = mlp_model.predict(test_dataset_norm)\n",
    "rf_predictions = rf_model.predict(test_dataset)\n",
    "\n",
    "# Get actual values\n",
    "actual_values = test_dataset.y.flatten()\n",
    "\n",
    "# Denormalize MLP predictions\n",
    "mlp_predictions_denorm = normalizer.untransform(test_dataset_norm)\n",
    "mlp_pred_values = mlp_predictions_denorm.y.flatten()\n",
    "rf_pred_values = rf_predictions.flatten()\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# MLP predictions\n",
    "ax1.scatter(actual_values, mlp_pred_values, alpha=0.7, color='blue', s=100)\n",
    "ax1.plot([min(actual_values), max(actual_values)], \n",
    "         [min(actual_values), max(actual_values)], 'r--', lw=2)\n",
    "ax1.set_xlabel('Actual LogP')\n",
    "ax1.set_ylabel('Predicted LogP')\n",
    "ax1.set_title('MLP Model Predictions')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest predictions\n",
    "ax2.scatter(actual_values, rf_pred_values, alpha=0.7, color='green', s=100)\n",
    "ax2.plot([min(actual_values), max(actual_values)], \n",
    "         [min(actual_values), max(actual_values)], 'r--', lw=2)\n",
    "ax2.set_xlabel('Actual LogP')\n",
    "ax2.set_ylabel('Predicted LogP')\n",
    "ax2.set_title('Random Forest Predictions')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print prediction details\n",
    "print(\"Test Set Predictions:\")\n",
    "for i, smiles in enumerate(test_dataset.ids):\n",
    "    print(f\"{smiles}: Actual={actual_values[i]:.2f}, \"\n",
    "          f\"MLP={mlp_pred_values[i]:.2f}, RF={rf_pred_values[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65f155",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478908db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Forest, we can get feature importance\n",
    "if hasattr(rf_model.model_instance, 'feature_importances_'):\n",
    "    feature_importance = rf_model.model_instance.feature_importances_\n",
    "    \n",
    "    # Get top 20 most important features\n",
    "    top_features_idx = np.argsort(feature_importance)[-20:]\n",
    "    top_features_importance = feature_importance[top_features_idx]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(top_features_importance)), top_features_importance)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('ECFP Bit Index')\n",
    "    plt.title('Top 20 Most Important ECFP Features (Random Forest)')\n",
    "    plt.yticks(range(len(top_features_importance)), top_features_idx)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Most important feature index: {top_features_idx[-1]}\")\n",
    "    print(f\"Highest importance value: {top_features_importance[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80902aee",
   "metadata": {},
   "source": [
    "## 9. Virtual Screening Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6594cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of virtual screening with new molecules\n",
    "new_molecules = [\n",
    "    'CC(C)C1=CC=C(C=C1)C(=O)O',  # Similar to ibuprofen\n",
    "    'CC1=CC=CC=C1C(=O)O',  # Toluic acid\n",
    "    'C1=CC=C(C=C1)CCO',  # Phenethyl alcohol\n",
    "    'CC(C)(C)C1=CC=CC=C1'  # tert-Butylbenzene\n",
    "]\n",
    "\n",
    "print(\"Virtual Screening Results:\")\n",
    "print(\"Predicting LogP for new molecules...\\n\")\n",
    "\n",
    "# Featurize new molecules\n",
    "new_features = ecfp_featurizer.featurize(new_molecules)\n",
    "new_dataset = dc.data.NumpyDataset(X=new_features, ids=new_molecules)\n",
    "\n",
    "# Make predictions\n",
    "rf_new_predictions = rf_model.predict(new_dataset)\n",
    "\n",
    "# Display results\n",
    "for i, smiles in enumerate(new_molecules):\n",
    "    predicted_logp = rf_new_predictions[i, 0]\n",
    "    \n",
    "    # Classify based on LogP\n",
    "    if predicted_logp < 1:\n",
    "        classification = \"Hydrophilic\"\n",
    "    elif predicted_logp < 3:\n",
    "        classification = \"Moderate\"\n",
    "    else:\n",
    "        classification = \"Lipophilic\"\n",
    "    \n",
    "    print(f\"Molecule: {smiles}\")\n",
    "    print(f\"  Predicted LogP: {predicted_logp:.2f}\")\n",
    "    print(f\"  Classification: {classification}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa69d4",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try the following:\n",
    "1. Load a real dataset from DeepChem (e.g., Tox21, BACE)\n",
    "2. Try different featurization methods (GraphConv, MPNN)\n",
    "3. Implement cross-validation for more robust evaluation\n",
    "4. Explore multi-task learning for predicting multiple properties\n",
    "5. Use graph neural networks for molecular property prediction\n",
    "\n",
    "## Next Steps\n",
    "- Explore DeepChem's built-in datasets\n",
    "- Learn about graph neural networks for molecules\n",
    "- Study transfer learning in drug discovery\n",
    "- Investigate uncertainty quantification in molecular predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
