#!/usr/bin/env python3
"""
Test script to verify VAE tensor compatibility fix
"""

import numpy as np
import torch
import torch.nn.functional as F


def test_vae_loss_function():
    """Test the fixed VAE loss function with various tensor shapes"""

    def vae_loss_function(recon_x, x, mu, logvar, beta=1.0):
        """VAE loss with KL divergence and reconstruction loss - FIXED VERSION"""
        # Reconstruction loss - using .reshape() instead of .view()
        recon_loss = F.cross_entropy(
            recon_x.reshape(-1, recon_x.size(-1)), x.reshape(-1), reduction="mean"
        )

        # KL divergence loss
        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)

        return recon_loss + beta * kl_loss, recon_loss, kl_loss

    print("üß™ Testing VAE Loss Function Fix")
    print("=" * 40)

    # Test parameters
    batch_size = 8
    seq_len = 64
    vocab_size = 50
    latent_dim = 32

    # Create test tensors with challenging memory layouts
    print(f"Creating test tensors...")
    print(f"  Batch size: {batch_size}")
    print(f"  Sequence length: {seq_len}")
    print(f"  Vocabulary size: {vocab_size}")
    print(f"  Latent dimension: {latent_dim}")

    # Test Case 1: Regular tensors
    print("\nüìã Test Case 1: Regular tensors")
    try:
        recon_x = torch.randn(batch_size, seq_len, vocab_size)
        x = torch.randint(0, vocab_size, (batch_size, seq_len))
        mu = torch.randn(batch_size, latent_dim)
        logvar = torch.randn(batch_size, latent_dim)

        total_loss, recon_loss, kl_loss = vae_loss_function(recon_x, x, mu, logvar)

        print(f"‚úÖ SUCCESS - Total loss: {total_loss.item():.4f}")
        print(f"   Reconstruction loss: {recon_loss.item():.4f}")
        print(f"   KL loss: {kl_loss.item():.4f}")

    except Exception as e:
        print(f"‚ùå FAILED - {type(e).__name__}: {e}")
        return False

    # Test Case 2: Realistic VAE training scenario
    print("\nüìã Test Case 2: Realistic VAE training scenario")
    try:
        # More realistic dimensions that match actual training
        recon_x = torch.randn(batch_size, seq_len, vocab_size)
        x = torch.randint(0, vocab_size, (batch_size, seq_len))
        mu = torch.randn(batch_size, latent_dim)
        logvar = torch.randn(batch_size, latent_dim)

        # This simulates the actual call pattern in the notebook
        total_loss, recon_loss, kl_loss = vae_loss_function(
            recon_x, x, mu, logvar, beta=0.5
        )

        print(f"‚úÖ SUCCESS - Total loss: {total_loss.item():.4f}")
        print(f"   Reconstruction loss: {recon_loss.item():.4f}")
        print(f"   KL loss: {kl_loss.item():.4f}")

    except Exception as e:
        print(f"‚ùå FAILED - {type(e).__name__}: {e}")
        return False

    # Test Case 3: Non-contiguous tensors
    print("\nüìã Test Case 3: Non-contiguous tensors")
    try:
        base_recon = torch.randn(batch_size * 2, seq_len, vocab_size)
        recon_x = base_recon[::2]  # Non-contiguous view

        base_x = torch.randint(0, vocab_size, (batch_size * 2, seq_len))
        x = base_x[::2]  # Non-contiguous view

        mu = torch.randn(batch_size, latent_dim)
        logvar = torch.randn(batch_size, latent_dim)

        total_loss, recon_loss, kl_loss = vae_loss_function(recon_x, x, mu, logvar)

        print(f"‚úÖ SUCCESS - Total loss: {total_loss.item():.4f}")
        print(f"   Reconstruction loss: {recon_loss.item():.4f}")
        print(f"   KL loss: {kl_loss.item():.4f}")

    except Exception as e:
        print(f"‚ùå FAILED - {type(e).__name__}: {e}")
        return False

    # Test Case 4: Different batch sizes
    print("\nüìã Test Case 4: Varying batch sizes")
    for test_batch_size in [1, 4, 16, 32]:
        try:
            recon_x = torch.randn(test_batch_size, seq_len, vocab_size)
            x = torch.randint(0, vocab_size, (test_batch_size, seq_len))
            mu = torch.randn(test_batch_size, latent_dim)
            logvar = torch.randn(test_batch_size, latent_dim)

            total_loss, recon_loss, kl_loss = vae_loss_function(recon_x, x, mu, logvar)

            print(f"   Batch {test_batch_size:2d}: ‚úÖ Loss = {total_loss.item():.4f}")

        except Exception as e:
            print(f"   Batch {test_batch_size:2d}: ‚ùå {type(e).__name__}")
            return False

    print("\nüéâ All VAE loss function tests passed!")
    print("‚úÖ Tensor compatibility issue has been resolved")
    return True


if __name__ == "__main__":
    success = test_vae_loss_function()
    if success:
        print("\n" + "=" * 50)
        print("üèÜ VAE TRAINING FIX VERIFIED SUCCESSFULLY")
        print("üöÄ Ready for VAE training in Day 2 notebook!")
        print("=" * 50)
    else:
        print("\n" + "=" * 50)
        print("‚ö†Ô∏è  VAE FIX VERIFICATION FAILED")
        print("üîß Additional debugging required")
        print("=" * 50)
